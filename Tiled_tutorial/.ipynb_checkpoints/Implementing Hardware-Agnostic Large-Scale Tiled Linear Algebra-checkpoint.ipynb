{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e3c6cf9",
   "metadata": {},
   "source": [
    "# Implementing Hardware-Agnostic Large-Scale Tiled Linear Algebra: Lessons in HPC Accessibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a74283c",
   "metadata": {},
   "source": [
    "##  Should every scientist become an HPC specialist to keep up with the demands of modern science? \n",
    "\n",
    "The amount of data created, consumed and stored in the world continues expanding\n",
    "\n",
    "![data](dataexpanding.png)\n",
    "\n",
    "To process this data, fast large linear algebra is key: linear algebra underlies many other computational methods, which are ultimately used for end applications to process these enourmous amounts of data.\n",
    "\n",
    "\n",
    "Over the past 50 years techhology has evolved enourmously and until recently grew with Moore's law: (Dongorra, e.a., arXiv: 2203.02544)\n",
    "* 1960 first supercomputers\n",
    "* 1976 vector processing\n",
    "* 1990 growth of multiprocessors\n",
    "* 2000 microchips and GPUs\n",
    "* 2020 cloud computing?\n",
    "Linear algebra has simultaneously evolved:\n",
    "* 1970 LINPACK vect operations\n",
    "* 1980 LAPACK tile and cache-optimization\n",
    "* 1990 ScaLAPACK multicore LAPACK\n",
    "* 2000 PLASMA scheduler\n",
    "* 2010: MAGMA GPU & hybrid\n",
    "* 2020 SLATE memory flexibility\n",
    "\n",
    "But recently Moore's law has been declared dead\n",
    "![moore](moore.png)\n",
    "\n",
    "And moreover, the memory bandwith per flop has not kept up with the increase in speed\n",
    "![memory](memory.png)\n",
    "\n",
    "Technology is no longer providing ‘free’ speed-up, and it was never 'free' to begin with. In 2024 Jack Dongorra said: \"[With every new computer] we scramble for the next three or four years to figure out how to use it effectively, [which is] an incredibly intensive process of redesigning algorithms !\" (Ashton, N., youtube, « EP8 ») In the post-Moore era new technologies arise to keep HPC advancing with the data growth (compilers, AI, ...), but all at the cost of additional complexity, preventing non-experts from using HPC for science.\n",
    "\n",
    "The dream is to have a full software-hardware separation with a single algorithm for all hardware levels.\n",
    "\n",
    "\n",
    "## In this tutorial we will propose an avenue to accesibility: a generic Tiled Linear Algebra Abstraction\n",
    "\n",
    "Our starting goal is to develop a very large Singular Value Decomposition (SVD), which is one of the most fundamental building block in large-data HPC applications as it reveals the best low-rank approximation of matrices. We will demonstrate the challenges that come when implementing a large SVD and how that demonstrates the need for a Tiled Linear Algebra Abstraction. SVD is used for data mining, image compression, optimization and many other computational methods.\n",
    "\n",
    "We will discuss:\n",
    "1. A refresher: the Singular Value Decomposition gives the best low-rank approximation of any matrix\n",
    "2. Multi-core computing and its challenges: existing building blocks do not provide flexibility\n",
    "3. KernelAbstractions.jl provides generic hardware-independent kernels\n",
    "4. Kernel building blocks can be hierarchically composed\n",
    "5. The roadmap to a future with accessible HPC: implementing abstractions\n",
    "\n",
    "Some material in this tutorial is based on the KernelAbstraction.jl documentation. Solutions to the 'tasks' in this tutorial can be found in the solutions.jl file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed7405f",
   "metadata": {},
   "source": [
    "# 0. Setting up the julia environment\n",
    "\n",
    "For every new project, it is recommended to set up a new environment to save package versions where your code is working. Load the package in your current folder upon startup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc76eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below commands were used to generate the environment\n",
    "#using Pkg; Pkg.activate(\".\");\n",
    "\n",
    "#Pkg.add([\"CUDA\",\"KernelAbstractions\", \"Dagger\", \"LinearAlgebra\", \"BenchmarkTools\", \"AMDGPU\", \"Plots\",\"Random\"]); \n",
    "#Pkg.update();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29ab0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify julia version (recommended 1.10 or 1.9)\n",
    "VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85b4290",
   "metadata": {},
   "source": [
    "Tip: in your c://user/.julia folder create a config/startup.jl file that activates your environment. This is how a startup.jl file could look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75567ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "ENV[\"JULIA_NUM_THREADS\"] = 4\n",
    "using Revise, Pkg\n",
    "Pkg.activate(\".\")\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1281375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the environment\n",
    "using Pkg;\n",
    "Pkg.activate(\".\");\n",
    "Pkg.instantiate();\n",
    "using CUDA, KernelAbstractions, Dagger, LinearAlgebra, BenchmarkTools, Plots, Random #AMDGPU\n",
    "include(\"QRkernels.jl\")\n",
    "include(\"solutions.jl\")\n",
    "CUDA.allowscalar(false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d305654",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the Following if you are using AMDGPU\n",
    "CuOrROCArray = CuArray   #ROCArray\n",
    "a=rand(Float32,2,2)\n",
    "agpu=CuOrROCArray(a)\n",
    "backend=KernelAbstractions.get_backend(agpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb208dd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8eab3741",
   "metadata": {},
   "source": [
    "# 1 A refresher: the Singular Value Decomposition gives the best low-rank approximation of any matrix\n",
    "\n",
    "The SVD decomposes a matrix into the product of a unitary matrix, a diagonal matrix and another unitary matrix. In contrast with eigenvalue decomposition, it can be calculated for a non-square matrix as well. \n",
    "![SVD](SVD.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b45f2fb",
   "metadata": {},
   "source": [
    "The SVD can be understood as finding an orthogonal basis for the row-space and column-space of a matrix.\n",
    "![SVDdefinition](SVDdef.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554b5eb5",
   "metadata": {},
   "source": [
    "One of its main applications is data compression. Consider matrix A with idd entries. A contains 50x60 data points. Its singular value decomposition will look like A= U * D * Vt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2b77aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=400\n",
    "A=randn(n,n)\n",
    "Asvd=svd(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43213e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "D=zeros(n,n)\n",
    "D[1:n+1:end].=Asvd.S\n",
    "Asvd.U * D * Asvd.Vt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8848d968",
   "metadata": {},
   "outputs": [],
   "source": [
    "Asvd.U * D * Asvd.Vt ≈ A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e286d12",
   "metadata": {},
   "source": [
    "When looking at the singular values, it is clear that the subsequent singular values rapidly decline: the first singular vectors are the main direction of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc0439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(Asvd.S, label= \"singular values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80a2aac",
   "metadata": {},
   "source": [
    "Thus, we can approximate matrix A reasonably well using the the first singular vectors and values, using only a fraction of the storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f892001",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff=200\n",
    "D=zeros(cutoff, cutoff)\n",
    "D[1:cutoff+1:end].=Asvd.S[1:cutoff]\n",
    "Adiff=abs.(Asvd.U[:,1:cutoff] * D * Asvd.Vt[1:cutoff,:] - A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dd2238",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm(Adiff)/norm(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d605d013",
   "metadata": {},
   "source": [
    "Let us consider this for different cutoff values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef260ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "approximation=zeros(n)\n",
    "for cutoff in 1:n\n",
    "    D=zeros(cutoff, cutoff)\n",
    "    D[1:cutoff+1:end].=Asvd.S[1:cutoff]\n",
    "    approximation[cutoff]=1-norm(abs.(Asvd.U[:,1:cutoff] * D * Asvd.Vt[1:cutoff,:] - A))./norm(A)\n",
    "end\n",
    "plot(approximation, label= \"Accuracy of approximation of order n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39aae49",
   "metadata": {},
   "source": [
    "# 2 Multi-core computing and its challenges: existing building blocks do not provide flexibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939eebeb",
   "metadata": {},
   "source": [
    "Let us examine the existing methods for singular value decomposition on the CPU and on the GPU and their shortcomings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469f3295",
   "metadata": {},
   "outputs": [],
   "source": [
    "T=Float32\n",
    "n=10\n",
    "a=rand(T,n,n)\n",
    "agpu=CuOrROCArray(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ed984",
   "metadata": {},
   "outputs": [],
   "source": [
    "svdvals!(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682ed8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "svdvals!(agpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f64d00",
   "metadata": {},
   "source": [
    "We can here see Julia's multiple dispatch at work: for Matrix types svdvals! points to LAPACK functions, while for CuArrays or ROCArrays it points to the vendor-specific implementations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6565d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@which svdvals!(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b516f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@which svdvals!(agpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c554bef6",
   "metadata": {},
   "source": [
    "All of these implementations have in common they use the tiled approach (although they might not use the QR algorithm by default). The tiled QR-based algorithm looks as follow: (source: Khairul Kabir, PhD diss, U. Tenessee, 2017)\n",
    "![TiledSVD](TiledSVD.png)\n",
    "We applied unitary transformations from the left and right, zero'ing out subsequent lines and columns until we have a banded diagonal matrix. This is step 1 of the full SVD algorithm. Step 2 brings the matrix further down to a bidiagonal, and step 3 reduces it to a diagonal, at which point we retrieve the singular values on the diagonal. (Unitary transformations preserve singular values.)\n",
    "![SVDsteps](SVDsteps.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a43667",
   "metadata": {},
   "source": [
    "Let's take a look at the performance of these functions for different matrix sizes and different element types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8c7e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_sizes=[10,40,100,400,1000] #if running on a supercomputer, go higher!\n",
    "timings=zeros(length(matrix_sizes), 4)\n",
    "for (i,n) in enumerate(matrix_sizes)\n",
    "    for (j,T) in enumerate([Float32, Float64])\n",
    "        a=rand(T,n,n)\n",
    "        agpu=CuOrROCArray(copy(a)) \n",
    "        timings[i,(j-1)*2+1]= @belapsed svd!($a, alg=LinearAlgebra.QRIteration())\n",
    "        #for the next line if you have AMDGPU, use AMDGPU.@sync svd!(agpu) \n",
    "        timings[i,(j-1)*2+2]= @belapsed CUDA.@sync svd!(agpu, alg=CUDA.CUSOLVER.QRAlgorithm()) \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae8948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(matrix_sizes, timings, labels= [\"F32 CPU\" \"F32 GPU\" \"F64 CPU\" \"F64 GPU\"], xaxis=:log10, yaxis=:log10, lw=2,\n",
    " xticks=(matrix_sizes, string.(matrix_sizes)), xlabel= \"matrix size nxn\", ylabel= \"time(s)\", legend=:bottomright)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6345a52d",
   "metadata": {},
   "source": [
    "**NOTE**: The standard SVD in AMDGPU is currently jacobi, which is slower at high matrix sizes. You will get skewed results with AMDGPU. We will get back later to the shortcomings of vendor-specific functionalities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1092dd1",
   "metadata": {},
   "source": [
    "We will be benchmarking a lot, the below function provides us a wrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a438b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "function mybenchmark(f, matrix_sizes, no_blocks, block_size, labels,  args...)\n",
    "    timings=zeros(length(matrix_sizes),length(labels)*2 )\n",
    "    for (i,n) in enumerate(matrix_sizes)\n",
    "        for (j,T) in enumerate([Float32, Float64])\n",
    "            a=rand(T,n,n)\n",
    "            agpu=CuOrROCArray(copy(a))  \n",
    "            f(timings, a, agpu,i,j, no_blocks[i], block_size, args...)\n",
    "        end\n",
    "    end\n",
    "    myplot = plot(matrix_sizes, timings, labels= reduce(hcat,[x.*labels for x in [\"F32 \" \"F64 \"]]), xaxis=:log10, yaxis=:log10, lw=2,\n",
    "     xticks=(matrix_sizes, string.(matrix_sizes)), xlabel= \"matrix size nxn\", ylabel= \"time(s)\",legend=:bottomright)\n",
    "    return timings, myplot\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25f0519",
   "metadata": {},
   "outputs": [],
   "source": [
    "function benchmark_builtin_svd!(timings, a, agpu,i,j, no_blocks, block_size)\n",
    "    timings[i,(j-1)*2+1]= @belapsed svd!($a, alg=LinearAlgebra.QRIteration())\n",
    "    svd!(copy(agpu), alg=CUDA.CUSOLVER.QRAlgorithm()) #run first to exclude pre-compilation time  (remove the alg keyword for AMDGPU)\n",
    "    #for the next line if you have AMDGPU, use AMDGPU.@sync svd!(agpu) \n",
    "    timings[i,(j-1)*2+2]= @elapsed CUDA.@sync svd!(agpu, alg=CUDA.CUSOLVER.QRAlgorithm()) \n",
    "end\n",
    "\n",
    "matrix_sizes=[10,40,100,400] #if running on a supercomputer, go higher!\n",
    "no_blocks=[1,1,1,1,1,1]\n",
    "block_size=1\n",
    "(timings, myplot) = mybenchmark(benchmark_builtin_svd!, matrix_sizes, no_blocks, block_size, [\"CPU\" \"GPU\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0bdf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(myplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27720258",
   "metadata": {},
   "source": [
    "The GPU implementations perform very well at sufficiently large matrix size (below the overhead is too significant), but cannot handle matrices larger than the GPU memory. Out-of-core algorithms move parts of the matrix to the GPU, performs there parallel-heavy tasks and then send the results back to the CPU where the full data is stored. \n",
    "\n",
    "**TASK**: We will start by implenting a tiled singular value decomposition using the existing julia and AMD/Nvidia building blocks. qr() for QR factorization and rmul!() or lmul!() to right-multiply or left-multiple. Fill the SVD function template below based on the tiled SVD as per the graph from (source: Khairul Kabir, PhD diss, U. Tenessee, 2017)\n",
    "![TiledSVD](TiledSVD.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3299eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TIP A[a:b,c:d] gives you the a-b row and the c-d column (use this for now, we will use views later)\n",
    "function mysvd!(A, no_blocks, block_size)\n",
    "    for k in 1:no_blocks\n",
    "        #TODO: fill template\n",
    "        \n",
    "        # STEP 1\n",
    "        # calculate the QR factorization of block k,k\n",
    "        # store the Q matrix\n",
    "        # replace block k,k with the R matrix\n",
    "        \n",
    "        for col in k+1:no_blocks\n",
    "            #STEP 2\n",
    "            # replace block k, col with itself left-multiplied by Q from step 1\n",
    "        end\n",
    "        \n",
    "        for row in k+1:no_blocks\n",
    "            \n",
    "            #STEP 3\n",
    "            #create the tall matrix by combining block k,k and block row,k\n",
    "            #calculate its QR factorization\n",
    "            #store the Q matrix\n",
    "            #replace block row, k by zeros\n",
    "            \n",
    "            for col in k+1:n\n",
    "                #STEP 4\n",
    "                #create the tall matrix by combining block k,col and block row,col\n",
    "                # left multiply this with Q from step 3\n",
    "                # replace both blocks with the outcome\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        k==no_blocks && break\n",
    "        \n",
    "        \n",
    "        #STEPS 5-8 are provided for you in the solution file as LQsweep_v1!(A, no_tiles, block_size) \n",
    "        LQsweep_v1!(A, no_blocks, block_size) \n",
    "        \n",
    "    end\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a727b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test your implementation here\n",
    "no_blocks=3\n",
    "block_size = 4\n",
    "A=randn(no_blocks*block_size,no_blocks*block_size)\n",
    "svd(A) ≈ svd(mysvd!(copy(A), no_blocks, block_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196097f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test your implementation for GPU here\n",
    "no_blocks= 3\n",
    "block_size = 4\n",
    "A=CuORROCArray(randn(no_blocks*block_size,no_blocks*block_size))\n",
    "svd(A) ≈ svd(mysvd!(copy(A), no_blocks, block_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f426388",
   "metadata": {},
   "source": [
    "Unless you already implemented a Tiled Abstraction, the code now probably looks hard to read, with a bunch of index calculations at each line. Let us put julia's multiple dispatch to work and develop a Tiled Abstraction to make this easier to read, debug and extend.\n",
    "\n",
    "**TASK**: Fill the TiledMatrix struct and functions templates below so that indices do not need to be calculated in every line, and then re-implement the singular value decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26a5fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct myTiledMatrix\n",
    "    tiles::Array{Union{SubArray,Array}}\n",
    "    tilesize::Int\n",
    "    no_tiles::Int\n",
    "end\n",
    "\n",
    "function myTiledMatrix(A::CuORROCArray{T, 2}, tile_size::Int, no_tiles::Int) where T\n",
    "    \n",
    "    tiles=Array{Array}(undef, no_tiles,no_tiles)\n",
    "    #define every tile by its indices using []\n",
    "    \n",
    "    return myTiledMatrix(tiles, tile_size:, no_tiles)\n",
    "end\n",
    "\n",
    "function returnfullmatrix(A::myTiledMatrix)\n",
    "    #create a zero matrix of the full size\n",
    "    #full every block form the tiles\n",
    "end\n",
    "\n",
    "function qr!(M::myTiledMatrix, #indices)\n",
    "    #implement qr of block i\n",
    "end\n",
    "function qr2!(M::TmyiledMatrix, #indices)\n",
    "    #implement qr of discontigous block\n",
    "end\n",
    "function mulq1!(M::myTiledMatrix, #indices)\n",
    "    #implement qr of discontigous block\n",
    "end\n",
    "function mulq2!(M::myTiledMatrix, #indices)\n",
    "    #implement qr of discontigous block\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "function mysvd_v2!(A::TiledMatrix)\n",
    "    # reimplement your SVD here\n",
    "    for k in 1:no_blocks\n",
    "        \n",
    "        for col in k+1:no_blocks\n",
    "                            \n",
    "        end\n",
    "        \n",
    "        for row in k+1:no_blocks\n",
    "            \n",
    "            \n",
    "            for col in k+1:n\n",
    "                                \n",
    "            end\n",
    "        end\n",
    "        \n",
    "        k==no_blocks && break\n",
    "                        \n",
    "        # for steps 5-8, keep LQ_mysvd!(A,no_blocks,block_size)\n",
    "        LQsweep_v1!(A, no_tiles, block_size)\n",
    "        # use this function for verifying correctness\n",
    "        # we will leave this out for performance benchmarking (next function)\n",
    "    end\n",
    "end\n",
    "function mysvd_v2_partial!(A::TiledMatrix)\n",
    "    # reimplement your SVD here\n",
    "    # ignore steps 5-8, for performance benchmarking\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c300bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_blocks=3\n",
    "block_size = 4\n",
    "A=CuOrROCArray(randn(no_blocks*block_size,no_blocks*block_size))\n",
    "TA=TiledMatrix(A,block_size, #other arguments)\n",
    "CUDA.@time mysvd_v2_partial!() #or @time AMD.GPU@sync mysvd_v2_partial!()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59b625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_blocks=3\n",
    "block_size = 4\n",
    "A=CuOrROCArray(randn(no_blocks*block_size,no_blocks*block_size))\n",
    "@btime svd!(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8368afb",
   "metadata": {},
   "source": [
    "Great, this looks a lot better! Let us verify whether the overhead this abstraction generates is reasonable. \n",
    "\n",
    "**TASK**:Benchmark your original SVD versus the one with a tiled abstraction on the CPU and GPU and plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7e7b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "function benchmark_tiles!(timings, a, agpu,i,j, no_blocks, block_size)\n",
    "    timings[i,(j-1)*4+1]= @belapsed #mysvd on CPU\n",
    "    #mysvd on GPU #remember to use @sync\n",
    "    #tiled CPU\n",
    "    #tiled GPU\n",
    "end\n",
    "\n",
    "#define matrix sizes, number of blocks and block sizes\n",
    "(timings, myplot) = mybenchmark(benchmark_tiles!, matrix_sizes, no_blocks, block_sizes, [\"mysvd CPU\" \"mysvd GPU\" \"tilesvd CPU\" \"tilesvd GPU\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a90a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(result_plot1()) #from solutions files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d147513",
   "metadata": {},
   "source": [
    "If all goes well, the plot should show the overhead being negligible: an advantage of julia's JIT compilation. Let us now benchmark this code against the built-in SVD calculators. While the banddiagonalization is only step 1 of the proces, it is typically the most time-consuming step: we want to ensure the performance is the same order of magnitude as the reference implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252ae14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "function benchmark_tiles!(timings, a, agpu,i,j, no_blocks, block_size)\n",
    "    #tiled CPU\n",
    "    #tiled GPU\n",
    "    #CPU SVD\n",
    "    #GPU SVD\n",
    "end\n",
    "\n",
    "#define matrix sizes, number of blocks and block sizes\n",
    "(timings, myplot) = mybenchmark(benchmark_tiles!, matrix_sizes, no_blocks, block_size, [\"tilesvd CPU\" \"tilesvd GPU\" \"LAPACK CPU\" \"GPU vendor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe05890",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(result_plot2())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da36f5ca",
   "metadata": {},
   "source": [
    "If all is right, the tiled code we wrote is significantly slower than the existing implementations. Let us examine the allocations of our SVD function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08b063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_blocks=3\n",
    "block_size = 4\n",
    "A=CuOrROCArray(randn(no_blocks*block_size,no_blocks*block_size))\n",
    "TA=TiledMatrix(A,block_size, #other arguments)\n",
    "CUDA.@time mysvd_v2_partial!() #or @time AMD.GPU@sync mysvd_v2_partial!()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90139778",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_blocks=3\n",
    "block_size = 4\n",
    "A=CuOrROCArray(randn(no_blocks*block_size,no_blocks*block_size))\n",
    "@btime svd!(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3d35a2",
   "metadata": {},
   "source": [
    "If you used A[] to access elements of a block instead of views(A,), and if you used qr() instead of qr!(), you should see a significant difference in number of allocations. At each execution of these functions, a copy is created. Let us verify whether this is indeed true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a37fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_blocks=3\n",
    "block_size = 4\n",
    "A=CuOrROCArray(randn(no_blocks*block_size,no_blocks*block_size))\n",
    "@btime A[3:5,3:5]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c16586",
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime view(A,3:5,3:5)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c61b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime qr(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9ab63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime qr!(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df248da6",
   "metadata": {},
   "source": [
    "Since we know the allocations are an issues, our next step is to attempt to remove them.\n",
    "\n",
    "**TASK**: rewrite your Tiled abstraction,Tiled Matrix functions to avoid copies, using views and in-place functions. (In-place functions have an exclamation mark at the end.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc73e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can re-use all the same function\n",
    "\n",
    "function myTiledMatrix2(A::CuORROCArray{T, 2}, tile_size::Int, no_tiles::Int) where T\n",
    "    \n",
    "    tiles=Array{Array}(undef, no_tiles,no_tiles)\n",
    "    #define every tile by its indices as a view\n",
    "    \n",
    "    return myTiledMatrix(tiles, tile_size:, no_tiles)\n",
    "end\n",
    "\n",
    "#rewrite these two functions using qr! in-place\n",
    "function qr!(M::myTiledMatrix, #indices)\n",
    "    #implement qr of block i\n",
    "end\n",
    "function qr2!(M::TmyiledMatrix, #indices)\n",
    "    #implement qr of discontigous block\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814c378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test your implementation here\n",
    "no_blocks=3\n",
    "block_size = 4\n",
    "A=randn(no_blocks*block_size,no_blocks*block_size)\n",
    "myTiledMatrix2(copy(A), block_size[i], no_blocks)\n",
    "mysvd_v2!(copy(A), no_blocks, block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b80f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test your implementation for GPU here\n",
    "no_blocks=3\n",
    "block_size = 4\n",
    "A=CuORROCArray(randn(no_blocks*block_size,no_blocks*block_size))\n",
    "myTiledMatrix2(copy(A), block_size[i], no_blocks)\n",
    "mysvd_v2!(copy(A), no_blocks, block_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abc4c54",
   "metadata": {},
   "source": [
    "If you are using a Nvidia GPU, you should get a few errors if you are trying to optimize qr! or taking a qr of non-contigous view: certain functions (e.g. non-contigous views) are not supported by Nvidia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e6916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10\n",
    "A=CuOrROCArray(randn(n,n))\n",
    "noncontigview=view(A, [1;2;4;5], 1:3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e81191",
   "metadata": {},
   "outputs": [],
   "source": [
    "qr!(noncontigview)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517d2c6f",
   "metadata": {},
   "source": [
    "Non-contigous views and AbstractMatrices (e.g. transposes of matrices) are some of the critical elements in julia language that make its development easier: it suffices to develop everything a single time, and thanks to the views functionality that same function can then also do the reverse operation. (e.g. LQ(X)=QR(X')) However, not all vendors support this and vendor support is often a big limiting factor in using functionalities unique to julia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168afe42",
   "metadata": {},
   "source": [
    "# 3 KernelAbstractions.jl provides generic hardware-independent kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69deef9e",
   "metadata": {},
   "source": [
    "However, we are not giving up on our large SVD just yet! Cue designing our own Kernels with KernelAbstractions: all of the julia capabilities are preserved and we can reach good performance over multiple vendors, without re-writing the code for each.KernelAbstractions provides hardware-agnostic kernel programming over Nvidia, AMD, Metal and Intel, so at this point we can develop a single kernel that will work for all users, rather than have to diverge. This is an example of a simple transpose kernel and its execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27ac605",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kernel function simple_transpose_kernel!(output, @Const(input))\n",
    "    I, J = @index(Global, NTuple)\n",
    "    @inbounds output[I, J] = input[J,I]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b21ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "T=Float32\n",
    "TILE_DIM=32\n",
    "N=TILE_DIM*8\n",
    "input = CuOrROCArray(rand!(allocate(backend, T, N, N)))\n",
    "output = similar(input)\n",
    "mykernel=simple_transpose_kernel!(backend, (TILE_DIM, TILE_DIM)) #compile kernel\n",
    "mykernel(input, output, ndrange=size(output)) #compile kernel\n",
    "KernelAbstractions.synchronize(backend)\n",
    "output ≈ input'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de61e817",
   "metadata": {},
   "source": [
    "As we know, on GPUs Communication inside a thread is faster than inside a block between threads, which is in turn faster than between blocks in a grid. We have not yet exploited that in the simple transpose kernel. Let us examine a kernel where local communication is prioritized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f34f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kernel function lmem_transpose_kernel!(output, @Const(input))\n",
    "    gi, gj = @index(Group, NTuple)\n",
    "    i, j = @index(Local,  NTuple)\n",
    "\n",
    "    N = @uniform @groupsize()[1]\n",
    "    M = @uniform @groupsize()[2]\n",
    "    \n",
    "    # +1 to avoid bank conflicts on shared memory\n",
    "    tile = @localmem eltype(output) (N+1, M) \n",
    "\n",
    "    # Manually calculate global indexes\n",
    "    # Later on we need to pivot the group index\n",
    "    I = (gi-1) * N + i\n",
    "    J = (gj-1) * M + j\n",
    "\n",
    "    @inbounds tile[i, j] = input[I, J]\n",
    "\n",
    "    @synchronize\n",
    "\n",
    "    # Pivot the group index\n",
    "    I = (gj-1) * M + i\n",
    "    J = (gi-1) * N + j\n",
    "\n",
    "    @inbounds output[I, J] = tile[j, i]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefa126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "T=Float32\n",
    "TILE_DIM=32\n",
    "N=TILE_DIM*8\n",
    "input = CuOrROCArray(rand!(allocate(backend, T, N, N)))\n",
    "output = similar(input)\n",
    "mykernel=lmem_transpose_kernel!(backend, (TILE_DIM, TILE_DIM)) #compile kernel\n",
    "mykernel(input, output, ndrange=size(output)) #execute kernel\n",
    "KernelAbstractions.synchronize(backend)\n",
    "output ≈ input'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd084f4",
   "metadata": {},
   "source": [
    "**TASK** : Benchmark and plot the performance of both kernels\n",
    "\n",
    "**CAREFUL!** To make sure the GPU is synchronized, run 'KernelAbstractions.synchronize(backend)' before and after the kernel execution, and include these in your timing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1800d44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function benchmark_transpose!(timings, a, agpu,i,j, no_blocks, block_size)\n",
    "    #simple kernel\n",
    "    #local memory kernels\n",
    "    #Careful: kernels passed as argument to @belapsed\n",
    "end\n",
    "\n",
    "#define matrix sizes, number of blocks and block sizes\n",
    "(timings, myplot) = mybenchmark(benchmark_transpose!, matrix_sizes, no_blocks, block_sizes, [\"simple\",\"lmem\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9f60cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(result_plot3())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f19f12d",
   "metadata": {},
   "source": [
    "**TASK**: Based on the transpose examples, write a matrix-matrix multiply kernel. Remember, blocks cannot communicate with each other inside a kernel, @synchronize only has effect on each block individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554fac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kernel function lmem_matmul_kernel!(output, @Const(input1), @Const(input2))\n",
    "    gi, gj = @index(Group, NTuple)\n",
    "    i, j = @index(Local,  NTuple)\n",
    "\n",
    "    N = @uniform @groupsize()[1]\n",
    "    M = @uniform @groupsize()[2]\n",
    "    \n",
    "   #declare the local memory you need\n",
    "    \n",
    "    #iterate over indices, load into local and calculate\n",
    "    \n",
    "    #write back to global memory\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73fb1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "T=Float32\n",
    "TILE_DIM=32\n",
    "N=TILE_DIM*8\n",
    "input1 = CuORROCArray(rand!(allocate(backend, T, N, N)))\n",
    "input2 = CuORROCArray(rand!(allocate(backend, T, N, N)))\n",
    "output = similar(input)\n",
    "mykernel=lmem_transpose_kernel!(backend, (TILE_DIM, TILE_DIM)) #compile kernel\n",
    "mykernel(output, input1, input2, ndrange=size(output)) #execute kernel\n",
    "KernelAbstractions.synchronize(backend)\n",
    "output ≈ input1*input2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a450c72",
   "metadata": {},
   "source": [
    "**TASK**: benchmark your implementations versus the reference implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80635269",
   "metadata": {},
   "outputs": [],
   "source": [
    "function benchmark_transpose!(timings, a, agpu,i,j, no_blocks, block_size)\n",
    "    #simple kernel\n",
    "    #local memory kernels\n",
    "end\n",
    "\n",
    "#define matrix sizes, number of blocks and block sizes\n",
    "(timings, myplot) = mybenchmark(benchmark_transpose!, matrix_sizes, no_blocks, block_sizes, [\"reference\",\"own\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a4142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(result_plot4())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e1264b",
   "metadata": {},
   "source": [
    "Now we can go back to our singular value decomposition. In the QRkernels file 6 kernels are provided for you:\n",
    "* QR1!(A::TiledMatrix, T, k) : for square matrix, replaces tile k,k with the QR decomposition\n",
    "* QR2!(A::TiledMatrix, T, row, k) : for tall matrix consisting of an uppertriangular top half (tile k,k) and bottom half (tile row,k), replaces the bottom matrix with the QR decomposition of the tall matrix\n",
    "* Qtapply1!(A::TiledMatrix, T, k, col) : applies the Q of the QR decomposition of tile k,k to tile k,col\n",
    "* Qtapply2!(A::TiledMatrix, T, k, col, row) : applies the Q of the QR decomposition of tall matrix consisting of tile k,k and tile row,k to the tall matrix conistsing of tile k,col and tile row, col\n",
    "* triu!(A::TiledMatrix,row,col): zeros the bottom lower triangular part of tile row,col\n",
    "\n",
    "T is a extra storage needed for the QR decomposition data, it is a CuOrRocArray for every tile. Below is the code given to create the storage.\n",
    "\n",
    "You can also use view(A,i,j).=0\n",
    "\n",
    "**TASK**: rewrite the tiled singular value decomposition using these kernels, and benchmark it against your allocation-heavy implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eef194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a TiledMatrix can be created as follows:\n",
    "A=TiledMatrix(A,blocksize,blocksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7abe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tau=Array{CuArray}(undef, no_blocks,no_blocks)\n",
    "for i in 1:no_blocks\n",
    "    for j in 1:no_blocks\n",
    "        Tau[i,j]=KernelAbstractions.zeros(backend, T, tilesize)\n",
    "    end\n",
    "end\n",
    "\n",
    "#Attention: The Tau calculated in QR1! and QR2! is the one that should be used for calculations in Qtapply1!, Qtapply2!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cffcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "function my_svd_v3!(A,T) \n",
    "\n",
    "    for k in 1:A.no_tiles\n",
    "        \n",
    "        #implement the first part of the SVD decomposition here\n",
    "\n",
    "        (k==A.no_tiles) && break\n",
    "\n",
    "        LQ1!(A,T,k) \n",
    "        LQtapply1_blocks!(A,T,k)\n",
    "        tril!(A,k,k+1)\n",
    "\n",
    "        for col in k+2:A.no_tiles \n",
    "            LQ2!(A,T,col,k)\n",
    "            LQtapply2_blocks!(A, T, col, k)\n",
    "            A.TileViews[col,k].=0\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94298dc7",
   "metadata": {},
   "source": [
    "# 4 Kernel building blocks can be hierarchically composed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6792e4eb",
   "metadata": {},
   "source": [
    "In the implementation above, we used a single QR kernel to calculate the QR factorization of the tile.However, QR and many other basic linear algebra operations can also be expressed as a tiled algorithm. In particular, this is really interesting for software-hardware matching: both consists of layers of locality with increasing communication-latency as we move up a layer of abstraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dab54c5",
   "metadata": {},
   "source": [
    "![recursive](recursive.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dffea60",
   "metadata": {},
   "source": [
    "**TASK**: In order to enable recursive tiling,create a new TiledTiledMatrix structure and redefine the QR decompositions. A tiled QR is given as tiled_QR!(A::TiledMatrix, T). No need to implement tiled Q multiply, or the tall QR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd83ca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct TiledTiledMatrix\n",
    "    TileTileViews::Array{Array{SubArray}}\n",
    "end\n",
    "\n",
    "function myTiledTiledMatrix2(A::CuORROCArray{T, 2}, blocksize::Int) where T\n",
    "    #calculate all tiles\n",
    "end\n",
    "function qr!(M::TiledTiledMatrix, i::row, j::col)\n",
    "    #implement qr of block i\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a2e6f2",
   "metadata": {},
   "source": [
    "# 5 The roadmap to a future with accessible HPC: implementing abstractions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7429da",
   "metadata": {},
   "source": [
    "![HPC](HPC.png)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
